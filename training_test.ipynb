{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "GPU is available!\n",
      "GPU Name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "\n",
    "# !pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "# !pip install -q -U transformers==\"4.39.1\"\n",
    "# !pip install -q accelerate==\"0.28.0\"\n",
    "# !pip install -q -i https://pypi.org/simple/ bitsandbytes==\"0.43.0\"\n",
    "# !pip install -q -U datasets==\"2.17.0\"\n",
    "# !pip install -q -U git+https://github.com/huggingface/trl\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft\n",
    "\n",
    "# !pip install torch==2.1.2 tensorboard\n",
    "# !pip install --upgrade transformers==4.38.2\n",
    "# !pip install datasets==2.16.1\n",
    "# !pip install accelerate==0.26.1\n",
    "# !pip install evaluate==0.4.1\n",
    "# !pip install bitsandbytes==0.42.0\n",
    "# !pip install trl==0.7.11\n",
    "# !pip install peft==0.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./data/all-data.csv\"\n",
    "\n",
    "df = pd.read_csv(filename, \n",
    "                 names=[\"sentiment\", \"text\"],\n",
    "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     2879\n",
       "positive    1363\n",
       "negative     604\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0   neutral   \n",
       "1   neutral   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "                                                                                                                                                                                                      text  \n",
       "0                                                                          According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .  \n",
       "1           Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .  \n",
       "2  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers ...  \n",
       "3  With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profi...  \n",
       "4  According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Split into training, test and eval data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train, test, and eval data are (900, 2), (900, 2), (150, 2)\n",
      "\n",
      "Break up by target column in train data is\n",
      "sentiment\n",
      "neutral     300\n",
      "positive    300\n",
      "negative    300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from main.feature_engineer import DataFrameSplitter\n",
    "\n",
    "\n",
    "splitter = DataFrameSplitter(df, train_size=300)\n",
    "\n",
    "# Perform the split to obtain train, test, and eval sets\n",
    "X_train_df, X_test_df, X_eval_df = splitter.split()\n",
    "X_test_df.to_csv(\"data/X_test_df.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print shapes and target column breakup of the train data\n",
    "print(f'Shape of train, test, and eval data are {X_train_df.shape}, {X_test_df.shape}, {X_eval_df.shape}')\n",
    "print(f'\\nBreak up by target column in train data is\\n{X_train_df.sentiment.value_counts()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.prompt_engineer import PromptGenerator\n",
    "\n",
    "# Assuming 'X_train_df', 'X_eval_df', and 'X_test_df' are your DataFrames containing text (and sentiment for 'X_train_df' and 'X_eval_df')\n",
    "prompt_generator = PromptGenerator()\n",
    "\n",
    "# Generate training and validation prompts\n",
    "X_train_df = prompt_generator.generate_dataframe_prompts(X_train_df, prompt_type='train')\n",
    "X_eval_df = prompt_generator.generate_dataframe_prompts(X_eval_df, prompt_type='train')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate test prompts\n",
    "y_true = X_test_df.sentiment\n",
    "X_test_df = prompt_generator.generate_dataframe_prompts(X_test_df, prompt_type='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pandas dataframe to Huggingface dataset\n",
    "train_data = Dataset.from_pandas(X_train_df)\n",
    "eval_data = Dataset.from_pandas(X_eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9adba8a05d4f78b2c79cbd6a0fc76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14c5d1e282b4701a80fe87bd19ab7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bfbc0a421045389a1a4f3520d34e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from main.model_base import QuantizedBaseModelInitializer\n",
    "\n",
    "# model_name = \"MaziyarPanahi/Mistral-7B-Instruct-v0.2\"\n",
    "#model_name = \"NousResearch/Llama-2-7b-hf\"'\n",
    "# model_name = \"mhenrichsen/gemma-7b\"\n",
    "# model_name = \"microsoft/phi-2\"\n",
    "# model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_name = \"NousResearch/Meta-Llama-3-8B-Instruct\"\n",
    "# Create an instance of QuantizedBaseModelInitializer\n",
    "initializer = QuantizedBaseModelInitializer(model_name)\n",
    "\n",
    "# Initialize the model and tokenizer with quantization\n",
    "model, tokenizer = initializer.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate Base Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c0be78e483452bb9451084e2204de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.332\n",
      "Accuracy for label 0: 0.000\n",
      "Accuracy for label 1: 0.973\n",
      "Accuracy for label 2: 0.023\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       300\n",
      "           1       0.33      0.97      0.49       300\n",
      "           2       0.47      0.02      0.04       300\n",
      "\n",
      "    accuracy                           0.33       900\n",
      "   macro avg       0.27      0.33      0.18       900\n",
      "weighted avg       0.27      0.33      0.18       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 300   0]\n",
      " [  0 292   8]\n",
      " [  0 293   7]]\n"
     ]
    }
   ],
   "source": [
    "from main.predict import ModelPredictor\n",
    "from main.evaluation import ModelEvaluator\n",
    "\n",
    "\n",
    "\n",
    "predictor = ModelPredictor(model, tokenizer)\n",
    "y_pred = predictor.predict(X_test_df)\n",
    "\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "evaluator.evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Fine-tune base model on given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PEFTModelTrainer.set_seed() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m PEFTModelTrainer(model, tokenizer, train_data, eval_data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Start the training process\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/llm_project/main/train_with_fine_tuning.py:98\u001b[0m, in \u001b[0;36mPEFTModelTrainer.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mExecutes the training process using PEFT.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_peft_config()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m51\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m training_arguments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_training_arguments()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Initialize the custom PEFT Trainer\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: PEFTModelTrainer.set_seed() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "from main.train_with_fine_tuning import PEFTModelTrainer\n",
    "trainer = PEFTModelTrainer(model, tokenizer, train_data, eval_data)\n",
    "\n",
    "# Start the training process\n",
    "trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Evaluate Fine-Tune Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f17ca936184c978d94ae9b27a66272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.872\n",
      "Accuracy for label 0: 0.933\n",
      "Accuracy for label 1: 0.873\n",
      "Accuracy for label 2: 0.810\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       300\n",
      "           1       0.79      0.87      0.83       300\n",
      "           2       0.88      0.81      0.85       300\n",
      "\n",
      "    accuracy                           0.87       900\n",
      "   macro avg       0.88      0.87      0.87       900\n",
      "weighted avg       0.88      0.87      0.87       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[280  17   3]\n",
      " [  9 262  29]\n",
      " [  3  54 243]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor = ModelPredictor(model, tokenizer)\n",
    "y_pred = predictor.predict(X_test_df)\n",
    "\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "evaluator.evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Predict with Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
